for(i in 1:length(x)) {
y <- y+1
}
}
total_file <- aggregate(x = book_words, by = list(book_words$file), FUN = conta)
total_file
total_file <- aggregate(x = book_words, by = list(book_words$file,book_words$word), FUN = conta)
total_file
conta <- function(x) {
y <- 0
for(i in 1:length(x)) {
y <- y+1
}
return(y)
}
total_file <- aggregate(x = book_words, by = list(book_words$file,book_words$word), FUN = conta)
total_file
book_words
total_file <- aggregate(x = book_words, by = list(book_words$word,book_words$file), FUN = conta)
total_file
melt(data = book_words)
melt(data = book_words,"file")
melt(data = book_words,"file","word")
melt(data = book_words,list("file","word"))
melt(data = book_words,id = c("file","word"))
summarise(book_words
summarise(book_words)
summary(book_words)
cast(book_words,n ~ file,count)
library("reshape")
cast(book_words,n ~ file,count)
t(book_words)
book_words
names(book_words) <- c("file","word","f")
book_words
total_file <- book_words[,-1]
total_file
aggregate(total_file,by = list(word),n)
aggregate(total_file,by = list("word"),n)
aggregate(total_file,by = list("word"))
aggregate(total_file,by = list("word"),sum)
aggregate(total_file,by = list(book_words$word),sum)
aggregate(total_file,by = list(book_words$word),sum(n))
aggregate(total_file,by = list(book_words$word),conta
aggregate(total_file,by = list(book_words$word),conta)
total_file <- aggregate(x = book_words, by = list(book_words$word,book_words$file), FUN = conta)
aggregate(total_file,by = list(book_words$word),conta)
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% ungroup() %>% as.data.frame()
book_words <- book_words[order(book_words$file),]
names(book_words) <- c("file","word","f")
total_file <- book_words[,-1]
total_file
aggregate(total_file,by = list(book_words$word),conta)
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% ungroup() %>% as.data.frame()
book_words <- book_words[order(book_words$file),]
names(book_words) <- c("file","word","f")
conta <- function(x) {
y <- 0
for(i in 1:length(x)) {
y <- y+1
}
return(f)
}
total_file <- book_words[,-1]
total_file <- aggregate(total_file,by = list(book_words$word),conta)
total_file <- book_words[,-2]
total_file
total_file <- book_words[,-1]
total_file
total_file <- aggregate(total_file,by = list(total_file$word),conta)
total_file
total_file <- book_words[,-1]
total_file <- aggregate(total_file,by = list(total_file$word),conta)
total_file
total_file <- book_words[,-1]
total_file
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% ungroup() %>% as.data.frame()
book_words <- book_words[order(book_words$file),]
names(book_words) <- c("file","word","f")
conta <- function(x) {
y <- 0
for(i in 1:length(x)) {
y <- y+1
}
return(f)
}
total_file <- book_words[,-1]
total_file
total_file <- book_words
total_file
total_file <- aggregate(total_file,by = list(total_file$file),conta)
conta <- function(x) {
y <- 0
for(i in 1:length(x)) {
y <- y+1
}
return(y)
}
total_file <- aggregate(total_file,by = list(total_file$file),conta)
total_file
total_file <- book_words
total_file
total_file <- aggregate(total_file,by = list(total_file$word),conta)
total_file
total_file <- total_file[-2:-3,]
total_file
total_file <- book_words
total_file <- aggregate(total_file,by = list(total_file$word),conta)
total_file <- total_file[,-2:-3]
total_file
book_words <- left_join(book_words, total_words, by = "word")
book_words <- left_join(book_file, total_words, by = "word")
book_words <- left_join(book_words, total_file, by = "word")
head(book_words)
total_file
names(total_file) <- c("word","f")
book_words <- left_join(book_words, total_file, by = "word")
head(book_words)
book_words
names(total_file) <- c("n","f")
head(book_words)
names(total_file) <- c("file","word","n","f")
head(book_words)
names(book_words) <- c("file","word","n","f")
head(book_words)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(term = word, document = file, n = f)
book_words
{
total_file <- book_words
total_file <- aggregate(total_file,by = list(total_file$word),conta)
total_file <- total_file[,-2:-3]
names(total_file) <- c("word","f")
book_words <- left_join(book_words, total_file, by = "word")
names(book_words) <- c("file","word","n","f")
head(book_words)
}
{
total_file <- book_words
total_file <- aggregate(total_file,by = list(total_file$word),conta)
total_file <- total_file[,-2:-3]
names(total_file) <- c("word","f")
book_words <- left_join(book_words, total_file, by = "word")
names(book_words) <- c("file","word","n","f")
head(book_words)
}
{
total_file <- book_words
total_file <- aggregate(total_file,by = list(total_file$word),conta)
total_file <- total_file[,-2:-3]
names(total_file) <- c("word","f")
book_words <- left_join(book_words, total_file, by = "word")
names(book_words) <- c("file","word","n","f")
head(book_words)
}
total_file <- book_words
total_file <- aggregate(total_file,by = list(total_file$word),conta)
total_file <- total_file[,-2:-3]
names(total_file) <- c("word","f")
book_words <- left_join(book_words, total_file, by = "word")
names(book_words) <- c("file","word","n","f")
head(book_words)
book_words <- book_words[order(book_words$file),]
names(book_words) <- c("file","word","f")
conta <- function(x) {
y <- 0
for(i in 1:length(x)) {
y <- y+1
}
return(y)
}
total_file <- book_words
total_file <- aggregate(total_file,by = list(total_file$word),conta)
total_file <- total_file[,-2:-3]
names(total_file) <- c("word","f")
book_words <- left_join(book_words, total_file, by = "word")
names(book_words) <- c("file","word","n","f")
head(book_words)
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% ungroup() %>% as.data.frame()
book_words <- book_words[order(book_words$file),]
names(book_words) <- c("file","word","f")
conta <- function(x) {
y <- 0
for(i in 1:length(x)) {
y <- y+1
}
return(y)
}
total_file <- book_words
total_file <- aggregate(total_file,by = list(total_file$word),conta)
total_file <- total_file[,-2:-3]
names(total_file) <- c("word","f")
book_words <- left_join(book_words, total_file, by = "word")
names(book_words) <- c("file","word","n","f")
head(book_words)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(term = word, document = file, n = n)
book_words <- as.data.table(book_words)
book_words
bind_tfidf <- function(tf,f) {
book_words$tfi <- 1+log2(book_words$tf)
book_words$idf <- log2(4/book_words$n)
book_words$tf_idf <- book_words$tfi * book_words$idf
return(book_words)
}
book_words
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% ungroup() %>% as.data.frame()
book_words <- book_words[order(book_words$file),]
names(book_words) <- c("file","word","f")
conta <- function(x) {
y <- 0
for(i in 1:length(x)) {
y <- y+1
}
return(y)
}
bind_tfidf <- function(tf,f) {
book_words$tfi <- 1+log2(book_words$tf)
book_words$idf <- log2(4/book_words$n)
book_words$tf_idf <- book_words$tfi * book_words$idf
return(book_words)
}
total_file <- book_words
total_file <- aggregate(total_file,by = list(total_file$word),conta)
total_file <- total_file[,-2:-3]
names(total_file) <- c("word","f")
book_words <- left_join(book_words, total_file, by = "word")
names(book_words) <- c("file","word","n","f")
head(book_words)
# Create matrix with TF-IDF
bind_tfidf(book_words$f,book_words$n)
bind_tfidf <- function(tf,n) {
book_words$tfi <- 1+log2(book_words$tf)
book_words$idf <- log2(4/book_words$n)
book_words$tf_idf <- book_words$tfi * book_words$idf
return(book_words)
}
# Create matrix with TF-IDF
bind_tfidf(book_words$f,book_words$n)
# Create matrix with TF-IDF
bind_tfidf(book_words$f,book_words$n)
bind_tfidf <- function(files = NULL,tf = tf,n = n) {
book_words$tfi <- 1+log2(book_words$tf)
book_words$idf <- log2(4/book_words$n)
book_words$tf_idf <- book_words$tfi * book_words$idf
return(book_words)
}
head(book_words)
bind_tfidf <- function(nfiles,tf,n) {
tfi <- 1+log2(tf)
idf <- log2(nfiles/n)
tf_idf <- tfi * idf
return(tf_idf)
}
# Create matrix with TF-IDF
bind_tfidf(book_words$f,book_words$n)
# Create matrix with TF-IDF
bind_tfidf(4,book_words$f,book_words$n)
book_words
bind_tfidf <- function(nfiles,f,n) {
tf <- 1+log2(f)
idf <- log2(nfiles/n)
tf_idf <- tf * idf
return(tfi,idf,tf_idf)
}
# Create matrix with TF-IDF
book_words <- bind_tfidf(4,book_words$f,book_words$n)
bind_tfidf <- function(nfiles,f,n) {
tf <- 1+log2(f)
idf <- log2(nfiles/n)
tf_idf <- tf * idf
return(c(tfi,idf,tf_idf))
}
# Create matrix with TF-IDF
book_words <- bind_tfidf(4,book_words$f,book_words$n)
bind_tfidf <- function(nfiles,f,n) {
tf <- 1+log2(f)
idf <- log2(nfiles/n)
tf_idf <- tf * idf
return(c(tf,idf,tf_idf))
}
# Create matrix with TF-IDF
book_words <- bind_tfidf(4,book_words$f,book_words$n)
book_words
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% ungroup() %>% as.data.frame()
book_words <- book_words[order(book_words$file),]
names(book_words) <- c("file","word","f")
conta <- function(x) {
y <- 0
for(i in 1:length(x)) {
y <- y+1
}
return(y)
}
bind_tfidf <- function(nfiles,f,n) {
tf <- 1+log2(f)
idf <- log2(nfiles/n)
tf_idf <- tf * idf
return(c(tf,idf,tf_idf))
}
total_file <- book_words
total_file <- aggregate(total_file,by = list(total_file$word),conta)
total_file <- total_file[,-2:-3]
names(total_file) <- c("word","f")
book_words <- left_join(book_words, total_file, by = "word")
names(book_words) <- c("file","word","n","f")
head(book_words)
# Create matrix with TF-IDF
book_words$tf_idf <- bind_tfidf(4,book_words$f,book_words$n)
book_words
book_words
bind_tfidf <- function(files,f,n) {
nfiles <- unique(files)
tf <- 1+log2(f)
idf <- log2(nfiles/n)
tf_idf <- tf * idf
return(c(tf,idf,tf_idf))
}
unique(book_words$file)
count(unique(book_words$file))
unique(book_words$file) %>% count()
unique(book_words$file) %>% sum
aggregate(unique(book_words$file))
aggregate(unique(book_words$file),count())
aggregate(unique(book_words$file),count
aggregate(unique(book_words$file),count)
aggregate(unique(book_words$file),sum)
dim(unique(book_words$file))
length(unique(book_words$file))
bind_tfidf <- function(files,f,n) {
nfiles <- length(unique(book_words$file))
tf <- 1+log2(f)
idf <- log2(nfiles/n)
tf_idf <- tf * idf
return(c(tf,idf,tf_idf))
}
bind_tfidf(book_words$file,book_words$f,book_words$n)
# Create matrix with TF-IDF
book_words$tf_idf <- bind_tfidf(book_words$file,book_words$f,book_words$n)
length(unique(book_words$file))
bind_tfidf <- function(files,f,n) {
nfiles <- length(unique(book_words$file))
tf <- 1+log2(f)
idf <- log2(4/n)
tf_idf <- tf * idf
return(c(tf,idf,tf_idf))
}
# Create matrix with TF-IDF
book_words$tf_idf <- bind_tfidf(book_words$file,book_words$f,book_words$n)
bind_tfidf <- function(files,f,n) {
nfiles <- length(unique(book_words$file))
tf <- 1+log2(f)
idf <- log2(4/n)
tf_idf <- tf * idf
book_words$df <- tf
book_words$idf <- idf
book_words$tf_idf <- tf_idf
}
# Create matrix with TF-IDF
book_words$tf_idf <- bind_tfidf(book_words$file,book_words$f,book_words$n)
book_words
source('E:/tf-idf/tf-idf.R')
source('E:/tf-idf/tf-idf.R')
print(book_words)
source('E:/tf-idf/tf-idf.R')
source('E:/tf-idf/tf-idf.R')
bind_tfidf(book_words$file,book_words$f,book_words$n)
bind_tfidf(book_words$file,book_words$f,book_words$n)
library(dplyr)
library(tidytext)
library(tm)
library(ggplot2)
library(dtplyr)
library("data.table")
bind_tfidf(book_words$file,book_words$f,book_words$n)
head(book_words)
book_words <- book_words[,-5]
head(book_words)
bind_tfidf(book_words$file,book_words$f,book_words$n)
head(book_words)
# Create matrix with TF-IDF
book_words$tf_idf <- bind_tfidf(book_words$file,book_words$f,book_words$n)
print(book_words)
source('E:/tf-idf/tf-idf.R')
source('E:/tf-idf/tf-idf.R')
nfiles
nfiles <- length(unique(book_words$file))
nfiles
rep(nfiles,nfiles)
rep(nfiles,length(book_words$file))
bind_tfidf <- function(files,f,n) {
nfiles <- length(unique(book_words$file))
nfiles <- rep(nfiles,length(book_words$file))
tf <- 1+log2(f)
idf <- log2(nfiles/n)
tf_idf <- tf * idf
book_words$df <- tf
book_words$idf <- idf
book_words$tf_idf <- tf_idf
}
source('E:/tf-idf/tf-idf.R')
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidytext)
library(ggplot2)
library(tm)
library(dtplyr)
library("data.table")
df1 <- readChar(con = "doc1.txt",nchars = 100)
df2 <- readChar(con = "doc2.txt",nchars = 100)
df3 <- readChar(con = "doc3.txt",nchars = 100)
df4 <- readChar(con = "doc4.txt",nchars = 100)
df1 <- cbind("doc1.txt",df1,"1")
df2 <- cbind("doc2.txt",df2,"2")
df3 <- cbind("doc3.txt",df3,"3")
df4 <- cbind("doc4.txt",df4,"4")
myDataset <- data.frame(stringsAsFactors = FALSE)
datasetTemp <- as.data.frame(rbind(df1,df2,df3,df4),stringsAsFactors = F)
names(datasetTemp) <- c("id","text","class")
datasetTemp
ct <- 0         # counter to read files
for(ind in 1:length(datasetTemp$id)) {
texto <- datasetTemp$text[ind]
texto <- paste(texto,collapse = " ")
texto <- gsub("<.*?>", "", texto)
documents <- Corpus(VectorSource(texto))
documents = tm_map(documents, tolower)
documents = tm_map(documents, removePunctuation)
texto  = tm_map(documents, removeNumbers)$content
#texto <- tm_map(documents, removeWords,stopwords("en"))$content
myDataset <- rbind(myDataset,c(datasetTemp$id[ind],datasetTemp$class[ind],
t(texto)),deparse.level = 0, stringsAsFactors =  FALSE)
}
myDataset <- data.frame(lapply(myDataset,as.character), stringsAsFactors = FALSE)
colnames(myDataset) <- c("file","class","text")
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% ungroup() %>% as.data.frame()
source('E:/tf-idf/tf-idf.R')
myDataset <- data.frame(lapply(myDataset,as.character), stringsAsFactors = FALSE)
colnames(myDataset) <- c("file","class","text")
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% ungroup() %>% as.data.frame()
book_words <- book_words[order(book_words$file),]
names(book_words) <- c("file","word","f")
ct <- 0         # counter to read files
for(ind in 1:length(datasetTemp$id)) {
texto <- datasetTemp$text[ind]
texto <- paste(texto,collapse = " ")
texto <- gsub("<.*?>", "", texto)
documents <- Corpus(VectorSource(texto))
documents = tm_map(documents, tolower)
documents = tm_map(documents, removePunctuation)
texto  = tm_map(documents, removeNumbers)$content
#texto <- tm_map(documents, removeWords,stopwords("en"))$content
myDataset <- rbind(myDataset,c(datasetTemp$id[ind],datasetTemp$class[ind],
t(texto)),deparse.level = 0, stringsAsFactors =  FALSE)
}
myDataset <- data.frame(lapply(myDataset,as.character), stringsAsFactors = FALSE)
colnames(myDataset) <- c("file","class","text")
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% ungroup() %>% as.data.frame()
book_words <- book_words[order(book_words$file),]
names(book_words) <- c("file","word","f")
conta <- function(x) {
y <- 0
for(i in 1:length(x)) {
y <- y+1
}
return(y)
}
print(df1)
print(readLines("dc1.txt"))
print(readLines("doc1.txt"))
print(readLines("doc1.txt"))
print(readLines("doc2.txt"))
print(readLines("doc3.txt"))
print(readLines("doc4.txt"))
print(readLines("doc1.txt"))
print(readLines("doc2.txt"))
print(readLines("doc3.txt"))
print(readLines("doc4.txt"))
paste("doc1 -",readLines("doc1.txt"))
print(readLines("doc1.txt"))
print(readLines("doc2.txt"))
print(readLines("doc3.txt"))
print(readLines("doc4.txt"))
total_file <- book_words
total_file <- aggregate(total_file,by = list(total_file$word),conta)
total_file <- total_file[,-2:-3]
names(total_file) <- c("word","f")
book_words <- left_join(book_words, total_file, by = "word")
names(book_words) <- c("file","word","n","f")
head(book_words)
# Create matrix with TF-IDF
book_words$tf_idf <- bind_tfidf(book_words$file,book_words$f,book_words$n)
print(book_words)
print(book_words)

myDataset <- rbind(myDataset,c(datasetTemp$id[ind],datasetTemp$class[ind],
t(texto)),deparse.level = 0, stringsAsFactors =  FALSE)
}
myDataset <- data.frame(lapply(myDataset,as.character), stringsAsFactors = FALSE)
colnames(myDataset) <- c("file","class","text")
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>%
ungroup()
total_words <- book_words %>% group_by(file) %>% summarize(total = sum(n))
book_words <- left_join(book_words, total_words)
head(book_words)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(word, file, n)
book_words <- as.data.table(book_words)
book_words$class <- myDataset[match(book_words$file,myDataset$file),"class"]
setkey(book_words,file,word,class)
write.csv(book_words,file = "tf-idf.csv")
book_words
df1 <- readLines(con = "doc1.txt")
df2 <- readLines(con = "doc2.txt")
df3 <- readLines(con = "doc3.txt")
df4 <- readLines(con = "doc4.txt")
df1 <- cbind("doc1.txt",df1,"1")
df2 <- cbind("doc2.txt",df2,"2")
df3 <- cbind("doc3.txt",df3,"3")
df4 <- cbind("doc4.txt",df4,"4")
myDataset <- data.frame(stringsAsFactors = FALSE)
datasetTemp <- as.data.frame(rbind(df1,df2,df3,df4),stringsAsFactors = F)
names(datasetTemp) <- c("id","text","class")
datasetTemp
ct <- 0         # counter to read files
for(ind in 1:length(datasetTemp$id)) {
texto <- datasetTemp$text[ind]
texto <- paste(texto,collapse = " ")
texto <- gsub("<.*?>", "", texto)
documents <- Corpus(VectorSource(texto))
documents = tm_map(documents, tolower)
documents = tm_map(documents, removePunctuation)
texto  = tm_map(documents, removeNumbers)$content
#texto <- tm_map(documents, removeWords,stopwords("en"))$content
myDataset <- rbind(myDataset,c(datasetTemp$id[ind],datasetTemp$class[ind],
t(texto)),deparse.level = 0, stringsAsFactors =  FALSE)
}
myDataset <- data.frame(lapply(myDataset,as.character), stringsAsFactors = FALSE)
colnames(myDataset) <- c("file","class","text")
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>%
ungroup()
total_words <- book_words %>% group_by(file) %>% summarize(total = sum(n))
book_words <- left_join(book_words, total_words)
head(book_words)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(word, file, n)
book_words <- as.data.table(book_words)
book_words$class <- myDataset[match(book_words$file,myDataset$file),"class"]
setkey(book_words,file,word,class)
write.csv(book_words,file = "tf-idf.csv")
book_words
df1 <- readLines(con = "doc1.txt",encoding = "utf-8")
df1 <- readLines(con = "doc1.txt",warn = T)
df1 <- readline("doc1.txt")
df1 <- readPlain("doc1.txt")
df1 <- readPlain(elem = "doc1.txt")
df1 <- readChar(con = "doc1.txt")
df1 <- readChar(con = "doc1.txt",nchars = 100)
df1 <- readChar(con = "doc1.txt",nchars = 100)
df2 <- readChar(con = "doc2.txt",nchars = 100)
df3 <- readChar(con = "doc3.txt",nchars = 100)
df4 <- readChar(con = "doc4.txt",nchars = 100)
df1 <- cbind("doc1.txt",df1,"1")
df2 <- cbind("doc2.txt",df2,"2")
df3 <- cbind("doc3.txt",df3,"3")
df4 <- cbind("doc4.txt",df4,"4")
myDataset <- data.frame(stringsAsFactors = FALSE)
datasetTemp <- as.data.frame(rbind(df1,df2,df3,df4),stringsAsFactors = F)
names(datasetTemp) <- c("id","text","class")
datasetTemp
ct <- 0         # counter to read files
for(ind in 1:length(datasetTemp$id)) {
texto <- datasetTemp$text[ind]
texto <- paste(texto,collapse = " ")
texto <- gsub("<.*?>", "", texto)
documents <- Corpus(VectorSource(texto))
documents = tm_map(documents, tolower)
documents = tm_map(documents, removePunctuation)
texto  = tm_map(documents, removeNumbers)$content
#texto <- tm_map(documents, removeWords,stopwords("en"))$content
myDataset <- rbind(myDataset,c(datasetTemp$id[ind],datasetTemp$class[ind],
t(texto)),deparse.level = 0, stringsAsFactors =  FALSE)
}
myDataset <- data.frame(lapply(myDataset,as.character), stringsAsFactors = FALSE)
colnames(myDataset) <- c("file","class","text")
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>%
ungroup()
total_words <- book_words %>% group_by(file) %>% summarize(total = sum(n))
book_words <- left_join(book_words, total_words)
head(book_words)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(word, file, n)
book_words <- as.data.table(book_words)
book_words$class <- myDataset[match(book_words$file,myDataset$file),"class"]
setkey(book_words,file,word,class)
write.csv(book_words,file = "tf-idf.csv")
book_words
df1 <- readChar(con = "doc1.txt",nchars = 100)
df2 <- readChar(con = "doc2.txt",nchars = 100)
df3 <- readChar(con = "doc3.txt",nchars = 100)
df4 <- readChar(con = "doc4.txt",nchars = 100)
df1 <- cbind("doc1.txt",df1,"1")
df2 <- cbind("doc2.txt",df2,"2")
df3 <- cbind("doc3.txt",df3,"3")
df4 <- cbind("doc4.txt",df4,"4")
myDataset <- data.frame(stringsAsFactors = FALSE)
datasetTemp <- as.data.frame(rbind(df1,df2,df3,df4),stringsAsFactors = F)
names(datasetTemp) <- c("id","text","class")
datasetTemp
ct <- 0         # counter to read files
for(ind in 1:length(datasetTemp$id)) {
texto <- datasetTemp$text[ind]
texto <- paste(texto,collapse = " ")
texto <- gsub("<.*?>", "", texto)
documents <- Corpus(VectorSource(texto))
documents = tm_map(documents, tolower)
documents = tm_map(documents, removePunctuation)
texto  = tm_map(documents, removeNumbers)$content
#texto <- tm_map(documents, removeWords,stopwords("en"))$content
myDataset <- rbind(myDataset,c(datasetTemp$id[ind],datasetTemp$class[ind],
t(texto)),deparse.level = 0, stringsAsFactors =  FALSE)
}
myDataset <- data.frame(lapply(myDataset,as.character), stringsAsFactors = FALSE)
colnames(myDataset) <- c("file","class","text")
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>%
ungroup()
total_words <- book_words %>% group_by(file) %>% summarize(total = sum(n))
book_words <- left_join(book_words, total_words)
head(book_words)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(word, file, n)
book_words <- as.data.table(book_words)
book_words$class <- myDataset[match(book_words$file,myDataset$file),"class"]
setkey(book_words,file,word,class)
write.csv(book_words,file = "tf-idf.csv")
book_words
head(book_words)
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>%
ungroup()
total_words <- book_words %>% group_by(file) %>% summarize(total = sum(n))
total_words
book_words
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>%
ungroup()
book_words
myDataset
book_words
book_words <- left_join(book_words, total_words)
head(book_words)
total_words
head(book_words)
n
file
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(word, file, total)
book_words <- as.data.table(book_words)
book_words$class <- myDataset[match(book_words$file,myDataset$file),"class"]
setkey(book_words,file,word,class)
write.csv(book_words,file = "tf-idf.csv")
book_words
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>%
ungroup()
total_words <- book_words %>% group_by(file) %>% summarize(total = sum(n))
book_words <- left_join(book_words, total_words)
head(book_words)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(word, file, total)
book_words
book_words <- as.data.table(book_words)
book_words
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>%
ungroup()
total_words <- book_words %>% group_by(file) %>% summarize(total = sum(n))
book_words <- left_join(book_words, total_words)
head(book_words)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(word, file, n)
book_words <- as.data.table(book_words)
book_words$class <- myDataset[match(book_words$file,myDataset$file),"class"]
setkey(book_words,file,word,class)
write.csv(book_words,file = "tf-idf.csv")
book_words
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>%
ungroup()
total_words <- book_words %>% group_by(file) %>% summarize(total = sum(n))
book_words <- left_join(book_words, total_words)
head(book_words)
book_words
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(tbl = word, document = file, n = n,term = word)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(tbl = word, document = file, n = n,term = word)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(tbl = word, document = file, n = n)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(word, file, n)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(word, file, n,total)
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>%
ungroup()
total_words <- book_words %>% group_by(file) %>% summarize(total = sum(n))
book_words <- left_join(book_words, total_words)
head(book_words)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(word, file, n,total)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(term = word, document = file, n = n)
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>%
ungroup()
total_words <- book_words %>% group_by(file) %>% summarize(total = sum(n))
book_words <- left_join(book_words, total_words)
head(book_words)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(term = word, document = file, n = n)
book_words
book_words <- as.data.table(book_words)
book_words
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>%
ungroup()
total_words <- book_words %>% group_by(file) %>% summarize(total = sum(n))
book_words <- left_join(book_words, total_words)
head(book_words)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(tbl = word, document = file, n = n)
book_words <- as.data.table(book_words)
book_words
head(book_words)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(tbl = word, document = file, n = n)
book_words <- as.data.table(book_words)
book_words
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(tbl = word, document = file, n = n)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(word, document = file, n = n)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(term = word, document = file, n = n)
head(book_words)
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>%
ungroup()
total_words <- book_words %>% group_by(file) %>% summarize(total = sum(n))
book_words <- left_join(book_words, total_words)
head(book_words)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(term = word, document = file, n = n)
book_words <- as.data.table(book_words)
book_words
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(term = word, document = file, n = total)
book_words <- as.data.table(book_words)
book_words
book_words %>%
select(-total) %>%
arrange(desc(tf_idf))
book_words
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>%
ungroup()
library(dplyr)
library(tidytext)
library(ggplot2)
library(tm)
library(dtplyr)
library("data.table")
head(book_words)
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>%
ungroup()
head(book_words)
total_words <- book_words %>% group_by(file) %>% summarize(total = sum(n))
total_words <- book_words %>% group_by(file) %>% summarize(total = sum(n))
book_words <- left_join(book_words, total_words)
head(book_words)
tidy(documents)
total_words <- book_words %>% group_by(word) %>% summarize(total = sum(n))
total_words
book_words <- left_join(book_words, total_words)
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>%
ungroup()
total_words <- book_words %>% group_by(word) %>% summarize(total = sum(n))
book_words <- left_join(book_words, total_words)
book_words <- left_join(book_words, total_words, by = "word")
head(book_words)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(term = word, document = file, n = total)
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>%
ungroup()
total_words <- book_words %>% group_by(word) %>% summarize(total = sum(n))
book_words <- left_join(book_words, total_words, by = "word")
head(book_words)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(term = word, document = file, n = total)
book_words <- as.data.table(book_words)
book_words$class <- myDataset[match(book_words$file,myDataset$file),"class"]
setkey(book_words,file,word,class)
write.csv(book_words,file = "tf-idf.csv")
book_words
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>%
ungroup()
total_words <- book_words %>% group_by(file,word) %>% summarize(total = sum(n))
book_words <- left_join(book_words, total_words, by = "word")
head(book_words)
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>%
ungroup()
total_words <- book_words %>% group_by(file,word) %>% summarize(total = sum(n))
book_words
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>%
ungroup()
book_words
total_words <- book_words %>% group_by(word) %>% summarize(total = sum(n))
book_words <- left_join(book_words, total_words, by = "word")
head(book_words)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(term = word, document = file, n = total)
book_words <- as.data.table(book_words)
book_words$class <- myDataset[match(book_words$file,myDataset$file),"class"]
setkey(book_words,file,word,class)
write.csv(book_words,file = "tf-idf.csv")
book_words
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>%
ungroup()
total_words <- book_words %>% group_by(word) %>% summarize(total = sum(n))
book_words <- left_join(book_words, total_words, by = "word")
head(book_words)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(term = word, document = file, n = n)
book_words <- as.data.table(book_words)
book_words$class <- myDataset[match(book_words$file,myDataset$file),"class"]
setkey(book_words,file,word,class)
write.csv(book_words,file = "tf-idf.csv")
book_words
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) #%>% ungroup()
total_words <- book_words %>% group_by(word) %>% summarize(total = sum(n))
book_words <- left_join(book_words, total_words, by = "word")
head(book_words)
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) #%>% ungroup()
total_words <- book_words %>% group_by(word) %>% summarize(total = sum(n))
book_words <- left_join(book_words, total_words, by = "word")
head(book_words)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(tbl = word, document = file, n = n)
book_words <- as.data.table(book_words)
book_words$class <- myDataset[match(book_words$file,myDataset$file),"class"]
setkey(book_words,file,word,class)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(tbl = book_words$word, document = file, n = n)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(tbl = total,term = word, document = file, n = n)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(tbl = total, document = file, n = n)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(term = word, document = file, n = n)
book_words <- as.data.table(book_words)
book_words$class <- myDataset[match(book_words$file,myDataset$file),"class"]
setkey(book_words,file,word,class)
write.csv(book_words,file = "tf-idf.csv")
book_words
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% ungroup()
total_words
myDataset
unnest_tokens(word, text,to_lower = TRUE)
myDataset %>%
unnest_tokens(word, text,to_lower = TRUE)
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% ungroup()
book_words
book_words <- myDataset %>%
unnest_tokens(file, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% ungroup()
book_words <- myDataset %>%
unnest_tokens(file, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% ungroup()
myDataset
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% group()
myDataset
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file, sort = TRUE) #%>% ungroup()
total_words
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file, sort = TRUE) #%>% ungroup()
total_words <- book_words %>% group_by(word) %>% summarize(total = sum(n))
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file, sort = TRUE) #%>% ungroup()
total_words <- book_words %>% group_by(word) %>% summarize(total = sum(n))
book_words
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file, sort = TRUE) %>% ungroup()
total_words <- book_words %>% group_by(word) %>% summarize(total = sum(n))
book_words
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file, sort = TRUE) %>% ungroup()
total_words <- book_words %>% group_by(word) %>% summarize(total = sum(n))
book_words
total_words <- book_words %>% group_by(file) %>% summarize(total = sum(n))
book_words <- left_join(book_words, total_words, by = "word")
book_words
book_words <- left_join(book_words, total_words, by = "file")
book_words
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file, sort = TRUE) %>% ungroup()
book_words
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% ungroup()
book_words
total_words <- book_words %>% group_by(file) %>% summarize(total = sum(n))
total_words
total_words <- book_words %>% group_by(word) %>% summarize(total = sum(n))
total_words
book_words <- left_join(book_words, total_words, by = "word")
head(book_words)
book_words
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(tbl = myDataset$text,term = word, document = file, n = n)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(tbl = word,term = word, document = file, n = n)
arrange(desc(tf_idf))
arrange(desc(book_words))
head(book_words)
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% ungroup()
total_words <- book_words %>% group_by(word) %>% summarize(total = sum(n))
book_words <- left_join(book_words, total_words, by = "word")
head(book_words)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(term = word, document = file, n = n)
book_words <- as.data.table(book_words)
book_words$class <- myDataset[match(book_words$file,myDataset$file),"class"]
setkey(book_words,file,word,class)
write.csv(book_words,file = "tf-idf.csv")
book_words
arrange(desc(book_words))
arrange(desc(tf-idf))
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(term = word, document = file, n = n) %>% arrange(desc(tf_idf))
book_words
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(term = word, document = file, n = n)
book_words
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% ungroup()
total_words <- book_words %>% group_by(word) %>% summarize(total = sum(n))
book_words <- left_join(book_words, total_words, by = "word")
head(book_words)
# Create matrix with TF-IDF
book_words <- book_words %>% bind_tf_idf(term = word, document = file, n = n)
book_words
book_words <- as.data.table(book_words)
book_words
sum(book_words$n)

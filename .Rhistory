book_words$tf_idf <- bind_tfidf(4,book_words$f,book_words$n)
book_words
book_words
bind_tfidf <- function(files,f,n) {
nfiles <- unique(files)
tf <- 1+log2(f)
idf <- log2(nfiles/n)
tf_idf <- tf * idf
return(c(tf,idf,tf_idf))
}
unique(book_words$file)
count(unique(book_words$file))
unique(book_words$file) %>% count()
unique(book_words$file) %>% sum
aggregate(unique(book_words$file))
aggregate(unique(book_words$file),count())
aggregate(unique(book_words$file),count
aggregate(unique(book_words$file),count)
aggregate(unique(book_words$file),sum)
dim(unique(book_words$file))
length(unique(book_words$file))
bind_tfidf <- function(files,f,n) {
nfiles <- length(unique(book_words$file))
tf <- 1+log2(f)
idf <- log2(nfiles/n)
tf_idf <- tf * idf
return(c(tf,idf,tf_idf))
}
bind_tfidf(book_words$file,book_words$f,book_words$n)
# Create matrix with TF-IDF
book_words$tf_idf <- bind_tfidf(book_words$file,book_words$f,book_words$n)
length(unique(book_words$file))
bind_tfidf <- function(files,f,n) {
nfiles <- length(unique(book_words$file))
tf <- 1+log2(f)
idf <- log2(4/n)
tf_idf <- tf * idf
return(c(tf,idf,tf_idf))
}
# Create matrix with TF-IDF
book_words$tf_idf <- bind_tfidf(book_words$file,book_words$f,book_words$n)
bind_tfidf <- function(files,f,n) {
nfiles <- length(unique(book_words$file))
tf <- 1+log2(f)
idf <- log2(4/n)
tf_idf <- tf * idf
book_words$df <- tf
book_words$idf <- idf
book_words$tf_idf <- tf_idf
}
# Create matrix with TF-IDF
book_words$tf_idf <- bind_tfidf(book_words$file,book_words$f,book_words$n)
book_words
source('E:/tf-idf/tf-idf.R')
source('E:/tf-idf/tf-idf.R')
print(book_words)
source('E:/tf-idf/tf-idf.R')
source('E:/tf-idf/tf-idf.R')
bind_tfidf(book_words$file,book_words$f,book_words$n)
bind_tfidf(book_words$file,book_words$f,book_words$n)
library(dplyr)
library(tidytext)
library(tm)
library(ggplot2)
library(dtplyr)
library("data.table")
bind_tfidf(book_words$file,book_words$f,book_words$n)
head(book_words)
book_words <- book_words[,-5]
head(book_words)
bind_tfidf(book_words$file,book_words$f,book_words$n)
head(book_words)
# Create matrix with TF-IDF
book_words$tf_idf <- bind_tfidf(book_words$file,book_words$f,book_words$n)
print(book_words)
source('E:/tf-idf/tf-idf.R')
source('E:/tf-idf/tf-idf.R')
nfiles
nfiles <- length(unique(book_words$file))
nfiles
rep(nfiles,nfiles)
rep(nfiles,length(book_words$file))
bind_tfidf <- function(files,f,n) {
nfiles <- length(unique(book_words$file))
nfiles <- rep(nfiles,length(book_words$file))
tf <- 1+log2(f)
idf <- log2(nfiles/n)
tf_idf <- tf * idf
book_words$df <- tf
book_words$idf <- idf
book_words$tf_idf <- tf_idf
}
source('E:/tf-idf/tf-idf.R')
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidytext)
library(ggplot2)
library(tm)
library(dtplyr)
library("data.table")
df1 <- readChar(con = "doc1.txt",nchars = 100)
df2 <- readChar(con = "doc2.txt",nchars = 100)
df3 <- readChar(con = "doc3.txt",nchars = 100)
df4 <- readChar(con = "doc4.txt",nchars = 100)
df1 <- cbind("doc1.txt",df1,"1")
df2 <- cbind("doc2.txt",df2,"2")
df3 <- cbind("doc3.txt",df3,"3")
df4 <- cbind("doc4.txt",df4,"4")
myDataset <- data.frame(stringsAsFactors = FALSE)
datasetTemp <- as.data.frame(rbind(df1,df2,df3,df4),stringsAsFactors = F)
names(datasetTemp) <- c("id","text","class")
datasetTemp
ct <- 0         # counter to read files
for(ind in 1:length(datasetTemp$id)) {
texto <- datasetTemp$text[ind]
texto <- paste(texto,collapse = " ")
texto <- gsub("<.*?>", "", texto)
documents <- Corpus(VectorSource(texto))
documents = tm_map(documents, tolower)
documents = tm_map(documents, removePunctuation)
texto  = tm_map(documents, removeNumbers)$content
#texto <- tm_map(documents, removeWords,stopwords("en"))$content
myDataset <- rbind(myDataset,c(datasetTemp$id[ind],datasetTemp$class[ind],
t(texto)),deparse.level = 0, stringsAsFactors =  FALSE)
}
myDataset <- data.frame(lapply(myDataset,as.character), stringsAsFactors = FALSE)
colnames(myDataset) <- c("file","class","text")
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% ungroup() %>% as.data.frame()
source('E:/tf-idf/tf-idf.R')
myDataset <- data.frame(lapply(myDataset,as.character), stringsAsFactors = FALSE)
colnames(myDataset) <- c("file","class","text")
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% ungroup() %>% as.data.frame()
book_words <- book_words[order(book_words$file),]
names(book_words) <- c("file","word","f")
ct <- 0         # counter to read files
for(ind in 1:length(datasetTemp$id)) {
texto <- datasetTemp$text[ind]
texto <- paste(texto,collapse = " ")
texto <- gsub("<.*?>", "", texto)
documents <- Corpus(VectorSource(texto))
documents = tm_map(documents, tolower)
documents = tm_map(documents, removePunctuation)
texto  = tm_map(documents, removeNumbers)$content
#texto <- tm_map(documents, removeWords,stopwords("en"))$content
myDataset <- rbind(myDataset,c(datasetTemp$id[ind],datasetTemp$class[ind],
t(texto)),deparse.level = 0, stringsAsFactors =  FALSE)
}
myDataset <- data.frame(lapply(myDataset,as.character), stringsAsFactors = FALSE)
colnames(myDataset) <- c("file","class","text")
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% ungroup() %>% as.data.frame()
book_words <- book_words[order(book_words$file),]
names(book_words) <- c("file","word","f")
conta <- function(x) {
y <- 0
for(i in 1:length(x)) {
y <- y+1
}
return(y)
}
print(df1)
print(readLines("dc1.txt"))
print(readLines("doc1.txt"))
print(readLines("doc1.txt"))
print(readLines("doc2.txt"))
print(readLines("doc3.txt"))
print(readLines("doc4.txt"))
print(readLines("doc1.txt"))
print(readLines("doc2.txt"))
print(readLines("doc3.txt"))
print(readLines("doc4.txt"))
paste("doc1 -",readLines("doc1.txt"))
print(readLines("doc1.txt"))
print(readLines("doc2.txt"))
print(readLines("doc3.txt"))
print(readLines("doc4.txt"))
total_file <- book_words
total_file <- aggregate(total_file,by = list(total_file$word),conta)
total_file <- total_file[,-2:-3]
names(total_file) <- c("word","f")
book_words <- left_join(book_words, total_file, by = "word")
names(book_words) <- c("file","word","n","f")
head(book_words)
# Create matrix with TF-IDF
book_words$tf_idf <- bind_tfidf(book_words$file,book_words$f,book_words$n)
print(book_words)
print(book_words)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidytext)
library(ggplot2)
library(tm)
library(dtplyr)
library("data.table")
total_file <- book_words
total_file <- aggregate(total_file,by = list(total_file$word),conta)
total_file <- total_file[,-2:-3]
names(total_file) <- c("word","f")
book_words <- left_join(book_words, total_file, by = "word")
total_file <- book_words
total_file <- aggregate(total_file,by = list(total_file$word),conta)
total_file <- total_file[,-2:-3]
names(total_file) <- c("word","f")
book_words <- left_join(book_words, total_file, by = "word")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidytext)
library(ggplot2)
library(tm)
library(dtplyr)
library("data.table")
df1 <- readChar(con = "doc1.txt",nchars = 100)
df2 <- readChar(con = "doc2.txt",nchars = 100)
df3 <- readChar(con = "doc3.txt",nchars = 100)
df4 <- readChar(con = "doc4.txt",nchars = 100)
df1 <- cbind("doc1.txt",df1,"1")
df2 <- cbind("doc2.txt",df2,"2")
df3 <- cbind("doc3.txt",df3,"3")
df4 <- cbind("doc4.txt",df4,"4")
myDataset <- data.frame(stringsAsFactors = FALSE)
datasetTemp <- as.data.frame(rbind(df1,df2,df3,df4),stringsAsFactors = F)
names(datasetTemp) <- c("id","text","class")
print(readLines("doc1.txt"))
print(readLines("doc2.txt"))
print(readLines("doc3.txt"))
print(readLines("doc4.txt"))
print(datasetTemp)
ct <- 0         # counter to read files
for(ind in 1:length(datasetTemp$id)) {
texto <- datasetTemp$text[ind]
texto <- paste(texto,collapse = " ")
texto <- gsub("<.*?>", "", texto)
documents <- Corpus(VectorSource(texto))
documents = tm_map(documents, tolower)
documents = tm_map(documents, removePunctuation)
texto  = tm_map(documents, removeNumbers)$content
#texto <- tm_map(documents, removeWords,stopwords("en"))$content
myDataset <- rbind(myDataset,c(datasetTemp$id[ind],datasetTemp$class[ind],
t(texto)),deparse.level = 0, stringsAsFactors =  FALSE)
}
myDataset <- data.frame(lapply(myDataset,as.character), stringsAsFactors = FALSE)
colnames(myDataset) <- c("file","class","text")
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% ungroup() %>% as.data.frame()
book_words <- book_words[order(book_words$file),]
names(book_words) <- c("file","word","f")
print(book_words)
conta <- function(x) {
y <- 0
for(i in 1:length(x)) {
y <- y+1
}
return(y)
}
bind_tfidf <- function(files,f,n) {
nfiles <- length(unique(book_words$file))
nfiles <- rep(nfiles,length(book_words$file))
tf <- 1+log2(f)
idf <- log2(nfiles/n)
tf_idf <- tf * idf
book_words$df <- tf
book_words$idf <- idf
book_words$tf_idf <- tf_idf
}
total_file <- book_words
total_file <- aggregate(total_file,by = list(total_file$word),conta)
total_file <- total_file[,-2:-3]
names(total_file) <- c("word","f")
book_words <- left_join(book_words, total_file, by = "word")
names(book_words) <- c("file","word","n","f")
head(book_words)
# Create matrix with TF-IDF
book_words$tf_idf <- bind_tfidf(book_words$file,book_words$f,book_words$n)
print(book_words)
df1 <- cbind(book_words[,file="doc1.txt"])
df1 <- book_words[,file="doc1.txt"]
df1 <- book_words[,file=="doc1.txt"]
print(book_words)
df1 <- book_words[,file="doc1.txt"]
df1 <- book_words[file="doc1.txt"]
df1 <- book_words[file="doc1.txt",]
df1 <- book_words[file="doc1.txt",]
df1 <- subset(book_words,select = file="doc1.txt")
df1 <- subset(book_words,file="doc1.txt")
df1
df1 <- subset(book_words,subset = file="doc1.txt")
df1 <- subset(book_words,subset = "doc1.txt")
df1 <- subset(book_words,subset = file=="doc1.txt")
df <- cbind(df1,df2,df3,df4)
df
df <- as.data.frame(cbind(df1,df2,df3,df4))
df
df1
word <- unique(book_words$file)
word <- unique(book_words$word)
word$n <- left_join(book_words$n,word,by = "word")
word <- left_join(book_words$n,word,by = "word")
word <- left_join(df1,word,by = "word")
word <- as.data.frame(word=unique(book_words$word))
word <- data.frame(word=unique(book_words$word))
word <- data.frame(word=unique(book_words$word),stringsAsFactors = F)
word <- left_join(df1,word,by = "word")
word <- data.frame(word=unique(book_words$word),stringsAsFactors = F)
word <- left_join(word,df1,by = "word")
word <- data.frame(word=unique(book_words$word),stringsAsFactors = F)
word <- left_join(word,df1,by = "word")
word <- left_join(word,df2,by = "word")
word <- left_join(word,df3,by = "word")
word <- left_join(word,df4,by = "word")
word
word <- data.frame(word=unique(book_words$word),stringsAsFactors = F)
word$file1 <- unique(book_words$file=="doc1.txt")
word$file1 <- unique(book_words[file=="doc1.txt"])
word$file1 <- 0
word$file2 <- 0
word$file3 <- 0
word$file4 <- 0
source('E:/tf-idf/tf-idf.R')
library(dplyr)
library(tidytext)
library(ggplot2)
library(tm)
library(dtplyr)
library("data.table")
df1 <- readChar(con = "doc1.txt",nchars = 100)
df1
df2 <- readChar(con = "doc2.txt",nchars = 100)
df3 <- readChar(con = "doc3.txt",nchars = 100)
df4 <- readChar(con = "doc4.txt",nchars = 100)
df1 <- cbind("doc1.txt",df1,"1")
df2 <- cbind("doc2.txt",df2,"2")
df3 <- cbind("doc3.txt",df3,"3")
df4 <- cbind("doc4.txt",df4,"4")
df1
myDataset <- data.frame(stringsAsFactors = FALSE)
datasetTemp <- as.data.frame(rbind(df1,df2,df3,df4),stringsAsFactors = F)
names(datasetTemp) <- c("id","text","class")
datasetTemp
datasetTemp
ct <- 0         # counter to read files
length(datasetTemp$id)
datasetTemp$text[1]
for(ind in 1:length(datasetTemp$id)) {
texto <- datasetTemp$text[ind]
texto <- paste(texto,collapse = " ")
texto <- gsub("<.*?>", "", texto)
documents <- Corpus(VectorSource(texto))
documents = tm_map(documents, tolower)
documents = tm_map(documents, removePunctuation)
texto  = tm_map(documents, removeNumbers)$content
#texto <- tm_map(documents, removeWords,stopwords("en"))$content
myDataset <- rbind(myDataset,c(datasetTemp$id[ind],datasetTemp$class[ind],
t(texto)),deparse.level = 0, stringsAsFactors =  FALSE)
}
myDataset <- data.frame(lapply(myDataset,as.character), stringsAsFactors = FALSE)
colnames(myDataset) <- c("file","class","text")
myDataset
book_words
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% ungroup() %>% as.data.frame()
book_words
book_words <- book_words[order(book_words$file),]
book_words
names(book_words) <- c("file","word","f")
book_words
conta <- function(x) {
y <- 0
for(i in 1:length(x)) {
y <- y+1
}
return(y)
}
bind_tfidf <- function(files,f,n) {
nfiles <- length(unique(book_words$file))
nfiles <- rep(nfiles,length(book_words$file))
tf <- 1+log2(f)
idf <- log2(nfiles/n)
tf_idf <- tf * idf
book_words$df <- tf
book_words$idf <- idf
book_words$tf_idf <- tf_idf
}
total_file <- book_words
total_file
total_file$word
total_file <- book_words
total_file <- aggregate(total_file,by = list(total_file$word),conta)
total_file
total_file <- total_file[,-2:-3]
names(total_file) <- c("word","f")
total_file
names(total_file) <- c("word","f")
book_words
book_words
book_words <- left_join(book_words, total_file, by = "word")
book_words
names(book_words) <- c("file","word","n","f")
head(book_words)
nfiles <- length(unique(book_words$file))
nfiles <- rep(nfiles,length(book_words$file))
nfiles
length(nfiles)
book_words$file
unique(book_words$file)
bind_tfidf <- function(files,f,n) {
nfiles <- length(unique(book_words$file))
nfiles <- rep(nfiles,length(book_words$file))
tf <- 1+log2(f)
idf <- log2(nfiles/n)
tf_idf <- tf * idf
book_words$tf <- tf
book_words$idf <- idf
book_words$tf_idf <- tf_idf
}
total_file <- book_words
total_file <- aggregate(total_file,by = list(total_file$word),conta)
total_file <- total_file[,-2:-3]
names(total_file) <- c("word","f")
book_words <- left_join(book_words, total_file, by = "word")
bind_tfidf <- function(files,f,n) {
nfiles <- length(unique(book_words$file))
nfiles <- rep(nfiles,length(book_words$file))
tf <- 1+log2(f)
idf <- log2(nfiles/n)
tf_idf <- tf * idf
book_words$df <- tf
book_words$idf <- idf
book_words$tf_idf <- tf_idf
}
total_file <- book_words
total_file <- aggregate(total_file,by = list(total_file$word),conta)
total_file <- total_file[,-2:-3]
names(total_file) <- c("word","f")
book_words <- left_join(book_words, total_file, by = "word")
source('E:/tf-idf/tf-idf.R')
library(dplyr)
library(tidytext)
library(ggplot2)
library(tm)
library(dtplyr)
df2 <- readChar(con = "doc2.txt",nchars = 100)
df4 <- readChar(con = "doc4.txt",nchars = 100)
df1 <- cbind("doc1.txt",df1,"1")
df2 <- cbind("doc2.txt",df2,"2")
df3 <- cbind("doc3.txt",df3,"3")
myDataset <- data.frame(stringsAsFactors = FALSE)
datasetTemp <- as.data.frame(rbind(df1,df2,df3,df4),stringsAsFactors = F)
names(datasetTemp) <- c("id","text","class")
datasetTemp
df1 <- readChar(con = "doc1.txt",nchars = 100)
df3 <- readChar(con = "doc3.txt",nchars = 100)
library("data.table")
df4 <- cbind("doc4.txt",df4,"4")
ct <- 0         # counter to read files
for(ind in 1:length(datasetTemp$id)) {
texto <- datasetTemp$text[ind]
texto <- paste(texto,collapse = " ")
texto <- gsub("<.*?>", "", texto)
documents <- Corpus(VectorSource(texto))
documents = tm_map(documents, tolower)
documents = tm_map(documents, removePunctuation)
texto  = tm_map(documents, removeNumbers)$content
#texto <- tm_map(documents, removeWords,stopwords("en"))$content
myDataset <- rbind(myDataset,c(datasetTemp$id[ind],datasetTemp$class[ind],
t(texto)),deparse.level = 0, stringsAsFactors =  FALSE)
}
myDataset <- data.frame(lapply(myDataset,as.character), stringsAsFactors = FALSE)
colnames(myDataset) <- c("file","class","text")
book_words <- myDataset %>%
unnest_tokens(word, text,to_lower = TRUE) %>%
count(file,word, sort = TRUE) %>% ungroup() %>% as.data.frame()
book_words <- book_words[order(book_words$file),]
names(book_words) <- c("file","word","f")
conta <- function(x) {
y <- 0
for(i in 1:length(x)) {
y <- y+1
}
return(y)
}
bind_tfidf <- function(files,f,n) {
nfiles <- length(unique(book_words$file))
nfiles <- rep(nfiles,length(book_words$file))
tf <- 1+log2(f)
idf <- log2(nfiles/n)
tf_idf <- tf * idf
book_words$df <- tf
book_words$idf <- idf
book_words$tf_idf <- tf_idf
}
total_file <- book_words
total_file <- aggregate(total_file,by = list(total_file$word),conta)
total_file <- total_file[,-2:-3]
names(total_file) <- c("word","f")
book_words <- left_join(book_words, total_file, by = "word")
names(book_words) <- c("file","word","n","f")
head(book_words)
# Create matrix with TF-IDF
book_words$tf_idf <- bind_tfidf(book_words$file,book_words$f,book_words$n)
print(book_words)
head(book_words,12)
sqrt(9)
head(book_words,12)
sqrt((9)^2)
sqrt((0-2)^2+(3-3)^2+(2.584963-0)^2+(1-0)^2+(0-2)^2+(0-2)^2+(0-2)^2+(0-2)^2)
